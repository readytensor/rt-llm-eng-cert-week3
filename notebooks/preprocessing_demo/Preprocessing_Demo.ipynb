{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a9a2ac55-3077-46c6-a444-e4d9c1a5ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q evaluate torch tqdm datasets peft transformers rouge_score hf_transfer colorama\n",
    "! pip install -q -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "08003a8b-8ece-4a0e-96e3-f4d0254373ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, load_from_disk, Dataset\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model, PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from pprint import pprint\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "745957f2-f79e-47a8-a7e9-c15985837e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dialogue': \"A: Hi!\\nB: Hello! How are you?\\nA: I'm great, thanks!\", 'summary': \"A greets B and says they're doing well.\"}\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    \"dialogue\": (\n",
    "        \"A: Hi!\\n\"\n",
    "        \"B: Hello! How are you?\\n\"\n",
    "        \"A: I'm great, thanks!\"\n",
    "    ),\n",
    "    \"summary\": \"A greets B and says they're doing well.\",\n",
    "}\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3eacabd4-dadc-4238-b64c-d9639a569be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "def visualize_chat_template_jupyter(text, show_newlines=True):\n",
    "    \"\"\"\n",
    "    Visualize chat template with colors in Jupyter notebooks.\n",
    "    Returns HTML object - use with display()\n",
    "    \"\"\"\n",
    "    import html\n",
    "    \n",
    "    # Escape HTML special characters\n",
    "    text = html.escape(text)\n",
    "    \n",
    "    # Make newlines visible\n",
    "    if show_newlines:\n",
    "        text = text.replace('\\n', '<span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>')\n",
    "    else:\n",
    "        text = text.replace('\\n', '<br>')\n",
    "    \n",
    "    # Color special tokens (cyan)\n",
    "    special_tokens = [\n",
    "        '&lt;|begin_of_text|&gt;',\n",
    "        '&lt;|start_header_id|&gt;',\n",
    "        '&lt;|end_header_id|&gt;',\n",
    "        '&lt;|eot_id|&gt;'\n",
    "    ]\n",
    "    for token in special_tokens:\n",
    "        text = text.replace(token, f'<span style=\"color: #00CED1; font-weight: bold;\">{token}</span>')\n",
    "    \n",
    "    # Color role headers\n",
    "    text = text.replace('system', '<span style=\"color: #FFD700; font-weight: bold; background: #3a3a00; padding: 2px 4px;\">system</span>')\n",
    "    text = text.replace('user', '<span style=\"color: #1E90FF; font-weight: bold; background: #001a33; padding: 2px 4px;\">user</span>')\n",
    "    text = text.replace('assistant', '<span style=\"color: #32CD32; font-weight: bold; background: #0d2d0d; padding: 2px 4px;\">assistant</span>')\n",
    "    \n",
    "    # Wrap in styled div\n",
    "    html_output = f'''\n",
    "    <div style=\"\n",
    "        font-family: 'Courier New', monospace; \n",
    "        background: #1e1e1e; \n",
    "        padding: 20px; \n",
    "        border-radius: 8px; \n",
    "        color: #d4d4d4;\n",
    "        font-size: 13px;\n",
    "        line-height: 1.6;\n",
    "        overflow-x: auto;\n",
    "        border: 2px solid #444;\n",
    "    \">\n",
    "        {text}\n",
    "    </div>\n",
    "    '''\n",
    "    \n",
    "    return HTML(html_output)\n",
    "\n",
    "\n",
    "def print_template_breakdown_jupyter(text):\n",
    "    \"\"\"\n",
    "    Structured breakdown for Jupyter with color-coded sections.\n",
    "    \"\"\"\n",
    "    sections_html = '<div style=\"font-family: Arial, sans-serif;\">'\n",
    "    sections_html += '<h3 style=\"color: #333;\">üìù CHAT TEMPLATE BREAKDOWN</h3>'\n",
    "    sections_html += '<hr style=\"border: 1px solid #ddd;\">'\n",
    "    \n",
    "    # Extract system\n",
    "    if '<|start_header_id|>system<|end_header_id|>' in text:\n",
    "        system_start = text.find('<|start_header_id|>system<|end_header_id|>') + len('<|start_header_id|>system<|end_header_id|>')\n",
    "        system_end = text.find('<|eot_id|>', system_start)\n",
    "        system_content = text[system_start:system_end].strip()\n",
    "        sections_html += f'''\n",
    "        <div style=\"margin: 15px 0; padding: 15px; background: #fff9e6; border-left: 4px solid #FFD700; border-radius: 4px;\">\n",
    "            <h4 style=\"color: #b8860b; margin: 0 0 10px 0;\">üü° SYSTEM</h4>\n",
    "            <pre style=\"margin: 0; white-space: pre-wrap; font-size: 12px;\">{system_content[:300]}</pre>\n",
    "        </div>\n",
    "        '''\n",
    "    \n",
    "    # Extract user\n",
    "    if '<|start_header_id|>user<|end_header_id|>' in text:\n",
    "        user_start = text.find('<|start_header_id|>user<|end_header_id|>') + len('<|start_header_id|>user<|end_header_id|>')\n",
    "        user_end = text.find('<|eot_id|>', user_start)\n",
    "        user_content = text[user_start:user_end].strip()\n",
    "        sections_html += f'''\n",
    "        <div style=\"margin: 15px 0; padding: 15px; background: #e6f2ff; border-left: 4px solid #1E90FF; border-radius: 4px;\">\n",
    "            <h4 style=\"color: #1E90FF; margin: 0 0 10px 0;\">üîµ USER (PROMPT)</h4>\n",
    "            <pre style=\"margin: 0; white-space: pre-wrap; font-size: 12px;\">{user_content[:300]}</pre>\n",
    "        </div>\n",
    "        '''\n",
    "    \n",
    "    # Extract assistant\n",
    "    if '<|start_header_id|>assistant<|end_header_id|>' in text:\n",
    "        asst_start = text.find('<|start_header_id|>assistant<|end_header_id|>') + len('<|start_header_id|>assistant<|end_header_id|>')\n",
    "        asst_end = text.find('<|eot_id|>', asst_start)\n",
    "        asst_content = text[asst_start:asst_end].strip()\n",
    "        sections_html += f'''\n",
    "        <div style=\"margin: 15px 0; padding: 15px; background: #e6ffe6; border-left: 4px solid #32CD32; border-radius: 4px;\">\n",
    "            <h4 style=\"color: #228b22; margin: 0 0 10px 0;\">üü¢ ASSISTANT (TRAINING TARGET)</h4>\n",
    "            <pre style=\"margin: 0; white-space: pre-wrap; font-size: 12px; font-weight: bold;\">{asst_content}</pre>\n",
    "            <p style=\"margin: 10px 0 0 0; color: #666; font-size: 11px;\">‚úÖ Only this section is used for loss calculation</p>\n",
    "        </div>\n",
    "        '''\n",
    "    \n",
    "    sections_html += '</div>'\n",
    "    \n",
    "    return HTML(sections_html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24107edf-2ff2-4077-8d7c-e29750219f2a",
   "metadata": {},
   "source": [
    "# Build Messages for Each Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b676e9-2d9c-496a-99ea-fc82c056f42a",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67ba9000-083c-4738-a654-89339fe43983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_prompt(dialogue: str, task_instruction: str) -> str:\n",
    "    \"\"\"Construct a summarization-style prompt given a dialogue and instruction.\"\"\"\n",
    "    return f\"{task_instruction}\\n\\n## Dialogue:\\n{dialogue}\\n## Summary:\"\n",
    "    \n",
    "\n",
    "def build_messages_for_sample(sample, task_instruction, include_assistant=False):\n",
    "    \"\"\"\n",
    "    Build a chat-style message list for a given sample, compatible with\n",
    "    models that use chat templates (like Llama 3).\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": build_user_prompt(sample[\"dialogue\"], task_instruction),\n",
    "        }\n",
    "    ]\n",
    "    if include_assistant:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": sample[\"summary\"]})\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c9fad-2efd-40ac-962f-ebbbedcfe3f0",
   "metadata": {},
   "source": [
    "### Task Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "30bdb9f9-f6a3-4b93-86bf-5334c6815a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a helpful assistant who writes concise, factual summaries of conversations. Summarize the following conversation into a single sentence. '"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_instruction = (\n",
    "    \"You are a helpful assistant who writes concise, factual summaries of conversations. \"\n",
    "    \"Summarize the following conversation into a single sentence. \"\n",
    ")\n",
    "\n",
    "task_instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c769c-f2f2-4105-ae88-64495d49b8d3",
   "metadata": {},
   "source": [
    "### Sample Messages With Assistant Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0fb95da3-4ecf-4e9f-93a1-addb90e77859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dialogue': \"A: Hi!\\nB: Hello! How are you?\\nA: I'm great, thanks!\", 'summary': \"A greets B and says they're doing well.\"}\n"
     ]
    }
   ],
   "source": [
    "## ORIGINAL SAMPLE\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b3c0d646-ec13-423b-a318-2e0b2fcf154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful assistant who writes concise, factual '\n",
      "             'summaries of conversations. Summarize the following conversation '\n",
      "             'into a single sentence. \\n'\n",
      "             '\\n'\n",
      "             '## Dialogue:\\n'\n",
      "             'A: Hi!\\n'\n",
      "             'B: Hello! How are you?\\n'\n",
      "             \"A: I'm great, thanks!\\n\"\n",
      "             '## Summary:',\n",
      "  'role': 'user'},\n",
      " {'content': \"A greets B and says they're doing well.\", 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "sample_messages_w_assistant_resp = build_messages_for_sample(sample, task_instruction, include_assistant=True)\n",
    "\n",
    "pprint(sample_messages_w_assistant_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d5b80-51b3-46a3-ba03-0330f6c9236d",
   "metadata": {},
   "source": [
    "### Sample Messages Without Assistant Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b6ff6f2a-2547-46db-9da7-522370e2700a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful assistant who writes concise, factual '\n",
      "             'summaries of conversations. Summarize the following conversation '\n",
      "             'into a single sentence. \\n'\n",
      "             '\\n'\n",
      "             '## Dialogue:\\n'\n",
      "             'A: Hi!\\n'\n",
      "             'B: Hello! How are you?\\n'\n",
      "             \"A: I'm great, thanks!\\n\"\n",
      "             '## Summary:',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "sample_messages_wo_assistant_resp = build_messages_for_sample(sample, task_instruction, include_assistant=False)\n",
    "\n",
    "pprint(sample_messages_wo_assistant_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786361e4-a0d6-4e98-ba6a-5ec540e75eb9",
   "metadata": {},
   "source": [
    "# Tokenization and Chat Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c84d5355-753f-48a4-94e3-782a89df7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac053bcb-fc6d-4f0a-8cab-e07efdcdb97b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original messages: \n",
      "[{'role': 'user', 'content': \"You are a helpful assistant who writes concise, factual summaries of conversations. Summarize the following conversation into a single sentence. \\n\\n## Dialogue:\\nA: Hi!\\nB: Hello! How are you?\\nA: I'm great, thanks!\\n## Summary:\"}, {'role': 'assistant', 'content': \"A greets B and says they're doing well.\"}]\n",
      "\n",
      "================================================================================\n",
      "After applying chat template: \n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 10 Nov 2025\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant who writes concise, factual summaries of conversations. Summarize the following conversation into a single sentence. \n",
      "\n",
      "## Dialogue:\n",
      "A: Hi!\n",
      "B: Hello! How are you?\n",
      "A: I'm great, thanks!\n",
      "## Summary:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "A greets B and says they're doing well.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "chat_full = tokenizer.apply_chat_template(\n",
    "    sample_messages_w_assistant_resp, tokenize=False, add_generation_prompt=False\n",
    ")\n",
    "\n",
    "print(f\"original messages: \\n{sample_messages_w_assistant_resp}\\n\")\n",
    "print(\"=\"*80)\n",
    "print(f\"After applying chat template: \\n{chat_full}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89208d64-67d6-4fd9-b4ab-a7fa502cfcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 10 Nov 2025\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are a helpful assistant who writes concise, factual summaries of conversations. Summarize the following conversation into a single sentence. \\n\\n## Dialogue:\\nA: Hi!\\nB: Hello! How are you?\\nA: I'm great, thanks!\\n## Summary:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_only = tokenizer.apply_chat_template(\n",
    "    sample_messages_wo_assistant_resp, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "chat_prompt_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6717fd04-0599-433d-b2e7-6b5823098d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"\n",
       "        font-family: 'Courier New', monospace; \n",
       "        background: #1e1e1e; \n",
       "        padding: 20px; \n",
       "        border-radius: 8px; \n",
       "        color: #d4d4d4;\n",
       "        font-size: 13px;\n",
       "        line-height: 1.6;\n",
       "        overflow-x: auto;\n",
       "        border: 2px solid #444;\n",
       "    \">\n",
       "        <span style=\"color: #00CED1; font-weight: bold;\">&lt;|begin_of_text|&gt;</span><span style=\"color: #00CED1; font-weight: bold;\">&lt;|start_header_id|&gt;</span><span style=\"color: #FFD700; font-weight: bold; background: #3a3a00; padding: 2px 4px;\">system</span><span style=\"color: #00CED1; font-weight: bold;\">&lt;|end_header_id|&gt;</span><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>Cutting Knowledge Date: December 2023<span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>Today Date: 10 Nov 2025<span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br><span style=\"color: #00CED1; font-weight: bold;\">&lt;|eot_id|&gt;</span><span style=\"color: #00CED1; font-weight: bold;\">&lt;|start_header_id|&gt;</span><span style=\"color: #1E90FF; font-weight: bold; background: #001a33; padding: 2px 4px;\">user</span><span style=\"color: #00CED1; font-weight: bold;\">&lt;|end_header_id|&gt;</span><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>You are a helpful <span style=\"color: #32CD32; font-weight: bold; background: #0d2d0d; padding: 2px 4px;\">assistant</span> who writes concise, factual summaries of conversations. Summarize the following conversation into a single sentence. <span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>## Dialogue:<span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>A: Hi!<span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>B: Hello! How are you?<span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>A: I&#x27;m great, thanks!<span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>## Summary:<span style=\"color: #00CED1; font-weight: bold;\">&lt;|eot_id|&gt;</span><span style=\"color: #00CED1; font-weight: bold;\">&lt;|start_header_id|&gt;</span><span style=\"color: #32CD32; font-weight: bold; background: #0d2d0d; padding: 2px 4px;\">assistant</span><span style=\"color: #00CED1; font-weight: bold;\">&lt;|end_header_id|&gt;</span><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>A greets B and says they&#x27;re doing well.<span style=\"color: #00CED1; font-weight: bold;\">&lt;|eot_id|&gt;</span>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"\n",
       "        font-family: 'Courier New', monospace; \n",
       "        background: #1e1e1e; \n",
       "        padding: 20px; \n",
       "        border-radius: 8px; \n",
       "        color: #d4d4d4;\n",
       "        font-size: 13px;\n",
       "        line-height: 1.6;\n",
       "        overflow-x: auto;\n",
       "        border: 2px solid #444;\n",
       "    \">\n",
       "        <span style=\"color: #00CED1; font-weight: bold;\">&lt;|begin_of_text|&gt;</span><span style=\"color: #00CED1; font-weight: bold;\">&lt;|start_header_id|&gt;</span><span style=\"color: #FFD700; font-weight: bold; background: #3a3a00; padding: 2px 4px;\">system</span><span style=\"color: #00CED1; font-weight: bold;\">&lt;|end_header_id|&gt;</span><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>Cutting Knowledge Date: December 2023<span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>Today Date: 10 Nov 2025<span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br><span style=\"color: #00CED1; font-weight: bold;\">&lt;|eot_id|&gt;</span><span style=\"color: #00CED1; font-weight: bold;\">&lt;|start_header_id|&gt;</span><span style=\"color: #1E90FF; font-weight: bold; background: #001a33; padding: 2px 4px;\">user</span><span style=\"color: #00CED1; font-weight: bold;\">&lt;|end_header_id|&gt;</span><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>You are a helpful <span style=\"color: #32CD32; font-weight: bold; background: #0d2d0d; padding: 2px 4px;\">assistant</span> who writes concise, factual summaries of conversations. Summarize the following conversation into a single sentence. <span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>## Dialogue:<span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>A: Hi!<span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>B: Hello! How are you?<span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>A: I&#x27;m great, thanks!<span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>## Summary:<span style=\"color: #00CED1; font-weight: bold;\">&lt;|eot_id|&gt;</span><span style=\"color: #00CED1; font-weight: bold;\">&lt;|start_header_id|&gt;</span><span style=\"color: #32CD32; font-weight: bold; background: #0d2d0d; padding: 2px 4px;\">assistant</span><span style=\"color: #00CED1; font-weight: bold;\">&lt;|end_header_id|&gt;</span><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br><span style=\"color: #ff1493; font-weight: bold;\">‚Üµ</span><br>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(visualize_chat_template_jupyter(chat_full))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "display(visualize_chat_template_jupyter(chat_prompt_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4741bc8f-f22d-4613-a1f0-65164cb2a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_samples(examples, tokenizer, task_instruction, max_length):\n",
    "    \"\"\"Tokenize dialogues and apply assistant-only masking for causal LM.\"\"\"\n",
    "    input_ids_list, labels_list, attn_masks = [], [], []\n",
    "\n",
    "    for d, s in zip(examples[\"dialogue\"], examples[\"summary\"]):\n",
    "        sample = {\"dialogue\": d, \"summary\": s}\n",
    "\n",
    "        # Build chat-style text\n",
    "        msgs_full = build_messages_for_sample(\n",
    "            sample, task_instruction, include_assistant=True\n",
    "        )\n",
    "        msgs_prompt = build_messages_for_sample(\n",
    "            sample, task_instruction, include_assistant=False\n",
    "        )\n",
    "\n",
    "        text_full = tokenizer.apply_chat_template(\n",
    "            msgs_full, tokenize=False, add_generation_prompt=False\n",
    "        )\n",
    "        text_prompt = tokenizer.apply_chat_template(\n",
    "            msgs_prompt, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        prompt_len = len(text_prompt)\n",
    "\n",
    "        tokens = tokenizer(\n",
    "            text_full,\n",
    "            max_length=max_length,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            add_special_tokens=False,\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "\n",
    "        # Mask non-assistant tokens\n",
    "        start_idx = len(tokens[\"input_ids\"])\n",
    "        for i, (start, _) in enumerate(tokens[\"offset_mapping\"]):\n",
    "            if start >= prompt_len:\n",
    "                start_idx = i\n",
    "                break\n",
    "\n",
    "        labels = [-100] * start_idx + tokens[\"input_ids\"][start_idx:]\n",
    "        input_ids_list.append(tokens[\"input_ids\"])\n",
    "        labels_list.append(labels)\n",
    "        attn_masks.append(tokens[\"attention_mask\"])\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids_list,\n",
    "        \"labels\": labels_list,\n",
    "        \"attention_mask\": attn_masks,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f81a00b1-c61e-4c59-bb79-f315e62a0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_dataset = Dataset.from_dict({\n",
    "    \"dialogue\": [sample[\"dialogue\"]],\n",
    "    \"summary\": [sample[\"summary\"]],\n",
    "})\n",
    "\n",
    "processed_samples = preprocess_samples(samples_dataset, tokenizer, task_instruction, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ff73ba6b-c7b5-4119-8712-2605fb9764b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "üìú ORIGINAL PROMPT SENT TO TOKENIZER\n",
      "============================\n",
      "You are a helpful assistant who writes concise, factual summaries of conversations. Summarize the following conversation into a single sentence.\n",
      "\n",
      "## Dialogue:\n",
      "A: Hi!\n",
      "B: Hello! How are you?\n",
      "A: I'm great, thanks!\n",
      "\n",
      "## Summary:\n",
      "============================\n",
      "\n",
      "Ground truth summary: \n",
      "A greets B and says they're doing well.\n",
      "\n",
      "============================\n",
      "\n",
      "                  token  input_id  attention_mask   label  masked\n",
      "0     <|begin_of_text|>    128000               1    -100    True\n",
      "1   <|start_header_id|>    128006               1    -100    True\n",
      "2                system      9125               1    -100    True\n",
      "3     <|end_header_id|>    128007               1    -100    True\n",
      "4                  \\n\\n       271               1    -100    True\n",
      "5                   Cut     38766               1    -100    True\n",
      "6                  ting      1303               1    -100    True\n",
      "7             Knowledge     33025               1    -100    True\n",
      "8                  Date      2696               1    -100    True\n",
      "9                     :        25               1    -100    True\n",
      "10             December      6790               1    -100    True\n",
      "11                            220               1    -100    True\n",
      "12                  202      2366               1    -100    True\n",
      "13                    3        18               1    -100    True\n",
      "14                   \\n       198               1    -100    True\n",
      "15                Today     15724               1    -100    True\n",
      "16                 Date      2696               1    -100    True\n",
      "17                    :        25               1    -100    True\n",
      "18                            220               1    -100    True\n",
      "19                   10       605               1    -100    True\n",
      "20                  Nov      4723               1    -100    True\n",
      "21                            220               1    -100    True\n",
      "22                  202      2366               1    -100    True\n",
      "23                    5        20               1    -100    True\n",
      "24                 \\n\\n       271               1    -100    True\n",
      "25           <|eot_id|>    128009               1    -100    True\n",
      "26  <|start_header_id|>    128006               1    -100    True\n",
      "27                 user       882               1    -100    True\n",
      "28    <|end_header_id|>    128007               1    -100    True\n",
      "29                 \\n\\n       271               1    -100    True\n",
      "30                  You      2675               1    -100    True\n",
      "31                  are       527               1    -100    True\n",
      "32                    a       264               1    -100    True\n",
      "33              helpful     11190               1    -100    True\n",
      "34            assistant     18328               1    -100    True\n",
      "35                  who       889               1    -100    True\n",
      "36               writes     14238               1    -100    True\n",
      "37              concise     64694               1    -100    True\n",
      "38                    ,        11               1    -100    True\n",
      "39              factual     61001               1    -100    True\n",
      "40            summaries     70022               1    -100    True\n",
      "41                   of       315               1    -100    True\n",
      "42        conversations     21633               1    -100    True\n",
      "43                    .        13               1    -100    True\n",
      "44                  Sum      8279               1    -100    True\n",
      "45                  mar      5730               1    -100    True\n",
      "46                  ize       553               1    -100    True\n",
      "47                  the       279               1    -100    True\n",
      "48            following      2768               1    -100    True\n",
      "49         conversation     10652               1    -100    True\n",
      "50                 into      1139               1    -100    True\n",
      "51                    a       264               1    -100    True\n",
      "52               single      3254               1    -100    True\n",
      "53             sentence     11914               1    -100    True\n",
      "54                    .        13               1    -100    True\n",
      "55                 \\n\\n      4815               1    -100    True\n",
      "56                   ##       567               1    -100    True\n",
      "57             Dialogue     70589               1    -100    True\n",
      "58                  :\\n       512               1    -100    True\n",
      "59                    A        32               1    -100    True\n",
      "60                    :        25               1    -100    True\n",
      "61                   Hi     21694               1    -100    True\n",
      "62                  !\\n      4999               1    -100    True\n",
      "63                    B        33               1    -100    True\n",
      "64                    :        25               1    -100    True\n",
      "65                Hello     22691               1    -100    True\n",
      "66                    !         0               1    -100    True\n",
      "67                  How      2650               1    -100    True\n",
      "68                  are       527               1    -100    True\n",
      "69                  you       499               1    -100    True\n",
      "70                  ?\\n      5380               1    -100    True\n",
      "71                    A        32               1    -100    True\n",
      "72                    :        25               1    -100    True\n",
      "73                    I       358               1    -100    True\n",
      "74                   'm      2846               1    -100    True\n",
      "75                great      2294               1    -100    True\n",
      "76                    ,        11               1    -100    True\n",
      "77               thanks      9523               1    -100    True\n",
      "78                  !\\n      4999               1    -100    True\n",
      "79                   ##       567               1    -100    True\n",
      "80              Summary     22241               1    -100    True\n",
      "81                    :        25               1    -100    True\n",
      "82           <|eot_id|>    128009               1    -100    True\n",
      "83  <|start_header_id|>    128006               1    -100    True\n",
      "84            assistant     78191               1    -100    True\n",
      "85    <|end_header_id|>    128007               1    -100    True\n",
      "86                 \\n\\n       271               1    -100    True\n",
      "87                    A        32               1      32   False\n",
      "88                  gre      2886               1    2886   False\n",
      "89                  ets      1441               1    1441   False\n",
      "90                    B       426               1     426   False\n",
      "91                  and       323               1     323   False\n",
      "92                 says      2795               1    2795   False\n",
      "93                 they       814               1     814   False\n",
      "94                  're      2351               1    2351   False\n",
      "95                doing      3815               1    3815   False\n",
      "96                 well      1664               1    1664   False\n",
      "97                    .        13               1      13   False\n",
      "98           <|eot_id|>    128009               1  128009   False\n"
     ]
    }
   ],
   "source": [
    "prompt_text = (\n",
    "    f\"{task_instruction.strip()}\\n\\n\"\n",
    "    f\"## Dialogue:\\n{sample['dialogue']}\\n\\n\"\n",
    "    \"## Summary:\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n============================\")\n",
    "print(\"üìú ORIGINAL PROMPT SENT TO TOKENIZER\")\n",
    "print(\"============================\")\n",
    "print(prompt_text)\n",
    "print(\"============================\\n\")\n",
    "print(f\"Ground truth summary: \\n{example['summary']}\\n\")\n",
    "print(\"============================\\n\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Visualize tokenization and masking\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Extract first example\n",
    "ex = {k: v[0] for k, v in processed_samples.items()}\n",
    "tokens = [tokenizer.decode([tid]) for tid in ex[\"input_ids\"]]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"token\": tokens,\n",
    "    \"input_id\": ex[\"input_ids\"],\n",
    "    \"attention_mask\": ex[\"attention_mask\"],\n",
    "    \"label\": ex[\"labels\"],\n",
    "})\n",
    "df[\"masked\"] = df[\"label\"].apply(lambda x: x == -100)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "print(df.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33909210-59fa-41cc-a27b-3e89769088e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
