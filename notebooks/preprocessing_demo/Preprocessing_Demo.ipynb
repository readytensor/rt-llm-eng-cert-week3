{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a9a2ac55-3077-46c6-a444-e4d9c1a5ace0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "! pip install -q evaluate torch tqdm datasets peft transformers rouge_score hf_transfer colorama\n",
    "! pip install -q -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08003a8b-8ece-4a0e-96e3-f4d0254373ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from pprint import pprint\n",
    "from IPython.display import display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b676e9-2d9c-496a-99ea-fc82c056f42a",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "67ba9000-083c-4738-a654-89339fe43983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_prompt(dialogue: str, task_instruction: str) -> str:\n",
    "    \"\"\"Construct a summarization-style prompt given a dialogue and instruction.\"\"\"\n",
    "    return f\"{task_instruction}\\n\\n## Dialogue:\\n{dialogue}\\n## Summary:\"\n",
    "    \n",
    "\n",
    "def build_messages_for_sample(sample, task_instruction, include_assistant=False):\n",
    "    \"\"\"\n",
    "    Build a chat-style message list for a given sample, compatible with\n",
    "    models that use chat templates (like Llama 3).\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": build_user_prompt(sample[\"dialogue\"], task_instruction),\n",
    "        }\n",
    "    ]\n",
    "    if include_assistant:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": sample[\"summary\"]})\n",
    "    return messages\n",
    "\n",
    "def preprocess_samples(examples, tokenizer, task_instruction, max_length):\n",
    "    \"\"\"Tokenize dialogues and apply assistant-only masking for causal LM.\"\"\"\n",
    "    input_ids_list, labels_list, attn_masks = [], [], []\n",
    "\n",
    "    for d, s in zip(examples[\"dialogue\"], examples[\"summary\"]):\n",
    "        sample = {\"dialogue\": d, \"summary\": s}\n",
    "\n",
    "        # Build chat-style text\n",
    "        msgs_full = build_messages_for_sample(\n",
    "            sample, task_instruction, include_assistant=True\n",
    "        )\n",
    "        msgs_prompt = build_messages_for_sample(\n",
    "            sample, task_instruction, include_assistant=False\n",
    "        )\n",
    "\n",
    "        text_full = tokenizer.apply_chat_template(\n",
    "            msgs_full, tokenize=False, add_generation_prompt=False\n",
    "        )\n",
    "        text_prompt = tokenizer.apply_chat_template(\n",
    "            msgs_prompt, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        prompt_len = len(text_prompt)\n",
    "\n",
    "        tokens = tokenizer(\n",
    "            text_full,\n",
    "            max_length=max_length,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            add_special_tokens=False,\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "\n",
    "        # Mask non-assistant tokens\n",
    "        start_idx = len(tokens[\"input_ids\"])\n",
    "        for i, (start, _) in enumerate(tokens[\"offset_mapping\"]):\n",
    "            if start >= prompt_len:\n",
    "                start_idx = i\n",
    "                break\n",
    "\n",
    "        labels = [-100] * start_idx + tokens[\"input_ids\"][start_idx:]\n",
    "        input_ids_list.append(tokens[\"input_ids\"])\n",
    "        labels_list.append(labels)\n",
    "        attn_masks.append(tokens[\"attention_mask\"])\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids_list,\n",
    "        \"labels\": labels_list,\n",
    "        \"attention_mask\": attn_masks,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4617b38d-4274-44db-8094-ba9bdeca5452",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a5d5ceda-15a4-429f-bcde-d7ec9c70f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "    \"dialogue\": (\n",
    "        \"A: Hi!\\n\"\n",
    "        \"B: Hello! How are you?\\n\"\n",
    "        \"A: I'm great, thanks!\"\n",
    "    ),\n",
    "    \"summary\": \"A greets B and says they're doing well.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "81ebf823-25e7-4e15-b636-edcccb1e6e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_instruction = (\n",
    "    \"You are a helpful assistant who writes concise, factual summaries of conversations. \"\n",
    "    \"Summarize the following conversation into a single sentence. \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "56042a68-f710-450b-af21-225f7a9efde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Convert to messages\n",
    "sample_messages_full = build_messages_for_sample(\n",
    "    sample,\n",
    "    task_instruction,\n",
    "    include_assistant=True\n",
    ")\n",
    "\n",
    "# STEP 2: Convert to chat template\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "chat_full = tokenizer.apply_chat_template(\n",
    "    sample_messages_full,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=False\n",
    ")\n",
    "\n",
    "# STEP 3/4: Tokenize and apply assistant-only masking\n",
    "samples_dataset = Dataset.from_dict({\n",
    "    \"dialogue\": [sample[\"dialogue\"]],\n",
    "    \"summary\": [sample[\"summary\"]],\n",
    "})\n",
    "processed_samples = preprocess_samples(samples_dataset, tokenizer, task_instruction, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ff73ba6b-c7b5-4119-8712-2605fb9764b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ“œ ORIGINAL EXAMPLE:\n",
      "\n",
      "{'dialogue': \"A: Hi!\\nB: Hello! How are you?\\nA: I'm great, thanks!\",\n",
      " 'summary': \"A greets B and says they're doing well.\"}\n",
      "================================================================================\n",
      "ðŸ“œ STEP 1: AFTER CONVERTING TO 'MESSAGES':\n",
      "\n",
      "[{'content': 'You are a helpful assistant who writes concise, factual '\n",
      "             'summaries of conversations. Summarize the following conversation '\n",
      "             'into a single sentence. \\n'\n",
      "             '\\n'\n",
      "             '## Dialogue:\\n'\n",
      "             'A: Hi!\\n'\n",
      "             'B: Hello! How are you?\\n'\n",
      "             \"A: I'm great, thanks!\\n\"\n",
      "             '## Summary:',\n",
      "  'role': 'user'},\n",
      " {'content': \"A greets B and says they're doing well.\", 'role': 'assistant'}]\n",
      "================================================================================\n",
      "STEP 2: AFTER APPLYING CHAT TEMPLATE: \n",
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 11 Nov 2025\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant who writes concise, factual summaries of conversations. Summarize the following conversation into a single sentence. \n",
      "\n",
      "## Dialogue:\n",
      "A: Hi!\n",
      "B: Hello! How are you?\n",
      "A: I'm great, thanks!\n",
      "## Summary:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "A greets B and says they're doing well.<|eot_id|>\n",
      "================================================================================\n",
      "STEP 3/4: AFTER TOKENIZATION AND MASKING: \n",
      "\n",
      "                  token  input_id  attention_mask   label  masked\n",
      "0     <|begin_of_text|>    128000               1    -100    True\n",
      "1   <|start_header_id|>    128006               1    -100    True\n",
      "2                system      9125               1    -100    True\n",
      "3     <|end_header_id|>    128007               1    -100    True\n",
      "4                  \\n\\n       271               1    -100    True\n",
      "5                   Cut     38766               1    -100    True\n",
      "6                  ting      1303               1    -100    True\n",
      "7             Knowledge     33025               1    -100    True\n",
      "8                  Date      2696               1    -100    True\n",
      "9                     :        25               1    -100    True\n",
      "10             December      6790               1    -100    True\n",
      "11                            220               1    -100    True\n",
      "12                  202      2366               1    -100    True\n",
      "13                    3        18               1    -100    True\n",
      "14                   \\n       198               1    -100    True\n",
      "15                Today     15724               1    -100    True\n",
      "16                 Date      2696               1    -100    True\n",
      "17                    :        25               1    -100    True\n",
      "18                            220               1    -100    True\n",
      "19                   11       806               1    -100    True\n",
      "20                  Nov      4723               1    -100    True\n",
      "21                            220               1    -100    True\n",
      "22                  202      2366               1    -100    True\n",
      "23                    5        20               1    -100    True\n",
      "24                 \\n\\n       271               1    -100    True\n",
      "25           <|eot_id|>    128009               1    -100    True\n",
      "26  <|start_header_id|>    128006               1    -100    True\n",
      "27                 user       882               1    -100    True\n",
      "28    <|end_header_id|>    128007               1    -100    True\n",
      "29                 \\n\\n       271               1    -100    True\n",
      "30                  You      2675               1    -100    True\n",
      "31                  are       527               1    -100    True\n",
      "32                    a       264               1    -100    True\n",
      "33              helpful     11190               1    -100    True\n",
      "34            assistant     18328               1    -100    True\n",
      "35                  who       889               1    -100    True\n",
      "36               writes     14238               1    -100    True\n",
      "37              concise     64694               1    -100    True\n",
      "38                    ,        11               1    -100    True\n",
      "39              factual     61001               1    -100    True\n",
      "40            summaries     70022               1    -100    True\n",
      "41                   of       315               1    -100    True\n",
      "42        conversations     21633               1    -100    True\n",
      "43                    .        13               1    -100    True\n",
      "44                  Sum      8279               1    -100    True\n",
      "45                  mar      5730               1    -100    True\n",
      "46                  ize       553               1    -100    True\n",
      "47                  the       279               1    -100    True\n",
      "48            following      2768               1    -100    True\n",
      "49         conversation     10652               1    -100    True\n",
      "50                 into      1139               1    -100    True\n",
      "51                    a       264               1    -100    True\n",
      "52               single      3254               1    -100    True\n",
      "53             sentence     11914               1    -100    True\n",
      "54                    .        13               1    -100    True\n",
      "55                 \\n\\n      4815               1    -100    True\n",
      "56                   ##       567               1    -100    True\n",
      "57             Dialogue     70589               1    -100    True\n",
      "58                  :\\n       512               1    -100    True\n",
      "59                    A        32               1    -100    True\n",
      "60                    :        25               1    -100    True\n",
      "61                   Hi     21694               1    -100    True\n",
      "62                  !\\n      4999               1    -100    True\n",
      "63                    B        33               1    -100    True\n",
      "64                    :        25               1    -100    True\n",
      "65                Hello     22691               1    -100    True\n",
      "66                    !         0               1    -100    True\n",
      "67                  How      2650               1    -100    True\n",
      "68                  are       527               1    -100    True\n",
      "69                  you       499               1    -100    True\n",
      "70                  ?\\n      5380               1    -100    True\n",
      "71                    A        32               1    -100    True\n",
      "72                    :        25               1    -100    True\n",
      "73                    I       358               1    -100    True\n",
      "74                   'm      2846               1    -100    True\n",
      "75                great      2294               1    -100    True\n",
      "76                    ,        11               1    -100    True\n",
      "77               thanks      9523               1    -100    True\n",
      "78                  !\\n      4999               1    -100    True\n",
      "79                   ##       567               1    -100    True\n",
      "80              Summary     22241               1    -100    True\n",
      "81                    :        25               1    -100    True\n",
      "82           <|eot_id|>    128009               1    -100    True\n",
      "83  <|start_header_id|>    128006               1    -100    True\n",
      "84            assistant     78191               1    -100    True\n",
      "85    <|end_header_id|>    128007               1    -100    True\n",
      "86                 \\n\\n       271               1    -100    True\n",
      "87                    A        32               1      32   False\n",
      "88                  gre      2886               1    2886   False\n",
      "89                  ets      1441               1    1441   False\n",
      "90                    B       426               1     426   False\n",
      "91                  and       323               1     323   False\n",
      "92                 says      2795               1    2795   False\n",
      "93                 they       814               1     814   False\n",
      "94                  're      2351               1    2351   False\n",
      "95                doing      3815               1    3815   False\n",
      "96                 well      1664               1    1664   False\n",
      "97                    .        13               1      13   False\n",
      "98           <|eot_id|>    128009               1  128009   False\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ðŸ“œ ORIGINAL EXAMPLE:\\n\")\n",
    "pprint(sample)\n",
    "print(\"=\" * 80)\n",
    "print(\"ðŸ“œ STEP 1: AFTER CONVERTING TO 'MESSAGES':\\n\")\n",
    "pprint(sample_messages_full)\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 2: AFTER APPLYING CHAT TEMPLATE: \\n\")\n",
    "print(chat_full)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Visualize tokenization and masking\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"STEP 3/4: AFTER TOKENIZATION AND MASKING: \\n\")\n",
    "\n",
    "# Extract first example\n",
    "ex = {k: v[0] for k, v in processed_samples.items()}\n",
    "tokens = [tokenizer.decode([tid]) for tid in ex[\"input_ids\"]]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"token\": tokens,\n",
    "    \"input_id\": ex[\"input_ids\"],\n",
    "    \"attention_mask\": ex[\"attention_mask\"],\n",
    "    \"label\": ex[\"labels\"],\n",
    "})\n",
    "df[\"masked\"] = df[\"label\"].apply(lambda x: x == -100)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1fe2b-994f-4708-9dff-a2919aa910d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
